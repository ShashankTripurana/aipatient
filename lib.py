import nltk
from nltk.tokenize import word_tokenize

# Test tokenization
text = "Hello, this is a test sentence."
tokens = word_tokenize(text)
print(tokens)
